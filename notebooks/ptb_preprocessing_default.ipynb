{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Default Preprocess For PTB data \n",
        "The default preprocessing step is what we conclude in our report. \n",
        "You can check below what should be input for this notebook and what would be the output if necessary.\n",
        "\n",
        "Processing **steps** for PTB dataset:   \n",
        "    resample: None   \n",
        "    rescaling: StandardScaler  \n",
        "\n",
        "\n",
        "**Input** : the original data.   \n",
        "ptbdb_normal.csv  \n",
        "ptbdb_abnormal.csv  \n",
        "\n",
        "**Output** : The cleaning data.   \n",
        "ptb_train_clean_default.csv  \n",
        "ptb_test_clean_default.csv  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local environment\n",
            "Current working directory: /Users/pingyuan/Documents/codeself/heartbeat-analysis-ai/notebooks\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "data_path = ''\n",
        "data_output_path = ''\n",
        "# Check if the environment is Google Colab\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running on Google Colab\")\n",
        "    # Install required libraries\n",
        "    !pip install scikit-learn -q\n",
        "    !pip install pandas -q\n",
        "    !pip install numpy -q\n",
        "    !pip install imbalanced-learn -q\n",
        "\n",
        "\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # set the path where the csv file stored in your google drive. \n",
        "    data_path = '/content/drive/MyDrive/Heartbeat_Project/'\n",
        "    data_output_path = data_path\n",
        "    \n",
        "else:\n",
        "    print(\"Running on local environment\")\n",
        "\n",
        "    current_path = os.getcwd()\n",
        "    print(\"Current working directory:\", current_path)\n",
        "    data_path = '../data/raw/'\n",
        "    data_output_path = '../data/processed/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "m_FSL5cYnEQI"
      },
      "outputs": [],
      "source": [
        "# Verify installation and import libraries\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "RawFiles = dict({\n",
        "    'normal': data_path +  'ptbdb_normal.csv',\n",
        "    'abnormal': data_path +  'ptbdb_abnormal.csv',\n",
        "})\n",
        "\n",
        "OutputFiles = dict({\n",
        "    'test': data_output_path +  'ptb_test_clean_default.csv',\n",
        "    'train': data_output_path +  'ptb_train_clean_default.csv',\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "hZhtCq2NnEQJ"
      },
      "outputs": [],
      "source": [
        "def addColumnsToDataframe(df):\n",
        "    \"\"\"\n",
        "    As the dataset is composed with 188 columns with the 188th columns as the category values,\n",
        "    so we give the last column the name 'target', others named with 'c_182'\n",
        "    \"\"\"\n",
        "    num_columns= df.shape[1]\n",
        "    feature_col_name = ['c_' + str(i) for i in range(0, num_columns - 1)]\n",
        "    df_columns = feature_col_name + ['target']\n",
        "    df.columns = df_columns\n",
        "    return df\n",
        "\n",
        "def convertColumnAsInt(df, column):\n",
        "    \"\"\"\n",
        "    As the category value is in float type. We want to get the int to identify the category.\n",
        "    \"\"\"\n",
        "    df[column] = df[column].astype(int)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ptb_normal = pd.read_csv(RawFiles.get('normal'), header=None ) \n",
        "ptb_abnormal = pd.read_csv(RawFiles.get('abnormal'), header=None )\n",
        "\n",
        "ptb_data = pd.concat([ptb_normal, ptb_abnormal], axis=0, ignore_index=True)\n",
        "\n",
        "ptb_data = addColumnsToDataframe(ptb_data)\n",
        "ptb_data = convertColumnAsInt(ptb_data, 'target')\n",
        "\n",
        "\n",
        "#drop null value  \n",
        "ptb_data = ptb_data.dropna(how='any')\n",
        "\n",
        "#no resampling for ptb data\n",
        "\n",
        "#rescaler with StandardScaler \n",
        "y = ptb_data['target']\n",
        "X = ptb_data.drop(columns=['target'], inplace=False)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#save clean data to \n",
        "# ptb_train_clean_default.csv\n",
        "# ptb_test_clean_default.csv\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=[f'c_{i}' for i in range(X.shape[1])])\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=[f'c_{i}' for i in range(X.shape[1])])\n",
        "y_train_df = pd.DataFrame(y_train, columns=['target'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['target'])\n",
        "\n",
        "\n",
        "ptb_train_clean_default = pd.concat(\n",
        "    [\n",
        "        X_train_scaled_df, y_train_df\n",
        "    ], axis=1)\n",
        "\n",
        "ptb_test_clean_default = pd.concat(\n",
        "    [  \n",
        "        X_test_scaled_df, y_test_df\n",
        "    ], axis=1)\n",
        "\n",
        "ptb_train_clean_default.to_csv(OutputFiles.get('train'), index=False)\n",
        "ptb_test_clean_default.to_csv(OutputFiles.get('test'), index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
