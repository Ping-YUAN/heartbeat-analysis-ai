{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global and Local Explanation for CNN model on MIT shifted data with binary target variable\n",
    "\n",
    "Input files:  \n",
    "Mode: `model_mit_binary_shift_cnn.h5` generated in notebook `modeling_mit_binary_shift_CNN.ipynb`     \n",
    "\n",
    "Dataset: Binary classification datate genereted in notebook `preprocessing_mit_binary_shift_minmax_oversampling.ipynb` \n",
    "\n",
    "\n",
    "mitbih_binary_train_shift_minmax_oversampling.csv \\\n",
    "mitbih_binary_test_shift_minmax_oversampling.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local environment\n",
      "Current working directory: g:\\Meine Ablage\\heartbeat-analysis-ai\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "data_path = ''\n",
    "model_output_path = ''\n",
    "# check if the enviorment is Google Colab \n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running on Google Colab\")\n",
    "    # Install required libraries\n",
    "    !pip install scikit-learn -q\n",
    "    !pip install pandas -q\n",
    "    !pip install numpy -q\n",
    "    !pip install imbalanced-learn -q\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # set the path where the csv file stored in your google drive. \n",
    "    data_path = '/content/drive/MyDrive/Heartbeat_Project/'\n",
    "    #model_output_path = data_path\n",
    "    model_path = data_path + 'model_mit_dnn_shift.h5' # pkl'\n",
    "\n",
    "else:\n",
    "    print(\"Running on local environment\")\n",
    "\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current working directory:\", current_path)\n",
    "    data_path = '../data/processed/'\n",
    "    model_output_path = '../models/'\n",
    "    model_path = '../models/' + 'model_mit_binary_shift_cnn.h5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation and import libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import shap\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawFiles = dict({\n",
    "    'train': data_path + 'mitbih_binary_train_shift_minmax_oversampling.csv', \n",
    "    'test': data_path + 'mitbih_binary_test_shift_minmax_oversampling.csv '  \n",
    "}) \n",
    "\n",
    "train = pd.read_csv(RawFiles.get('train'),sep=',',header=0)\n",
    "test = pd.read_csv(RawFiles.get('test'),sep=',',header=0)\n",
    "\n",
    "y_train = train['target']\n",
    "X_train = train.drop('target', axis=1)\n",
    "\n",
    "y_test = test['target']\n",
    "X_test = test.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation - Loss: 0.06615962088108063, Accuracy: 0.9800335168838501, AUC: 0.9903005957603455\n"
     ]
    }
   ],
   "source": [
    "# # Define model_path based on model_output_path\n",
    "# model_path = model_output_path + 'model_mit_dnn.pkl'\n",
    "\n",
    "# # Load the DNN model from the pickle file\n",
    "# with open(model_path, 'rb') as file:\n",
    "#     dnn_model = pickle.load(file)\n",
    "\n",
    "# # Check the type of the model (Sequential)\n",
    "# print(f\"Model type: {type(dnn_model)}\")\n",
    "\n",
    "# # Print the summary of the DNN model to understand its architecture\n",
    "# dnn_model.summary()\n",
    "\n",
    "# Load and compile the model\n",
    "try:\n",
    "    loaded_model = load_model(model_path, compile=False)\n",
    "except OSError as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    sys.exit(\"Check model path and try again.\")\n",
    "\n",
    "# Compile the model (ensuring metrics match expected inputs)\n",
    "loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_metrics = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Model Evaluation - Loss: {evaluation_metrics[0]}, Accuracy: {evaluation_metrics[1]}, AUC: {evaluation_metrics[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following we apply explanation strategies (SHAP, LIME) on the resampled (Oversampling) and rescaled (MinMax Scaler) and shifted dataset to explain the most important features within the CNN model due to to given strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# # Prepare background data for SHAP and calculate SHAP values\n",
    "# background = X_train.sample(1000, random_state=42).values  # Sample background data for SHAP\n",
    "# X_test_array = X_test.values  # Convert X_test to a numpy array\n",
    "\n",
    "# Reshape X_train and X_test to match the expected input shape of the model\n",
    "background = X_train.sample(1000, random_state=42).values.reshape(-1, X_train.shape[1], 1)\n",
    "X_test_array = X_test.values.reshape(-1, X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DeepExplainer with reshaped background data\n",
    "explainer = shap.DeepExplainer(loaded_model, background)\n",
    "\n",
    "# Compute SHAP values for test data\n",
    "shap_values = explainer.shap_values(X_test_array)\n",
    "\n",
    "# Visualize SHAP values (e.g., summary plot)\n",
    "shap.summary_plot(shap_values[0], X_test_array.squeeze(), feature_names=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize DeepExplainer with background data\n",
    "# explainer = shap.DeepExplainer(loaded_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute SHAP values for each feature and sample\n",
    "# shap_values = explainer.shap_values(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "\n",
    "# Calculate mean absolute SHAP values across all test samples for each feature\n",
    "mean_shap_values = np.mean(np.abs(shap_values), axis=0)\n",
    "\n",
    "# Verify that mean_shap_values is 1-dimensional\n",
    "print(\"Shape of mean_shap_values before flattening:\", mean_shap_values.shape)\n",
    "if mean_shap_values.ndim > 1:\n",
    "    mean_shap_values = mean_shap_values.flatten()  # Flatten if it's multi-dimensional\n",
    "print(\"Shape of mean_shap_values after flattening:\", mean_shap_values.shape)\n",
    "\n",
    "# Verify the number of features matches\n",
    "print(\"Number of features (X_test.columns):\", len(X_test.columns))\n",
    "print(\"Length of mean_shap_values:\", len(mean_shap_values))\n",
    "\n",
    "# Ensure lengths match before creating DataFrame\n",
    "if len(mean_shap_values) == len(X_test.columns):\n",
    "    # Create DataFrame for feature importance\n",
    "    shap_importance_df = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance': mean_shap_values\n",
    "    })\n",
    "\n",
    "    # Sort by importance and display top features\n",
    "    shap_importance_df = shap_importance_df.sort_values(by='importance', ascending=False)\n",
    "    print(\"Top 10 most important features based on SHAP values:\\n\", shap_importance_df.head(10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 10 most important features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(\n",
    "    x='importance', \n",
    "    y='feature', \n",
    "    data=shap_importance_df.head(10), \n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('SHAP: Top 10 Most Important Features for DNN Model')\n",
    "plt.xlabel('Mean Absolute SHAP Value')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for predict_proba behavior\n",
    "def predict_proba_wrapper(data):\n",
    "    # Predict using the model (outputs probabilities for binary classification)\n",
    "    predictions = loaded_model.predict(data)\n",
    "    # Reshape predictions to have two columns for binary classification: [1 - prediction, prediction]\n",
    "    return np.column_stack([1 - predictions, predictions])\n",
    "\n",
    "# Initialize the LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),  # Features from the training data\n",
    "    training_labels=np.array(y_train),  # Target labels for training data\n",
    "    mode=\"classification\",  # Set to 'classification' for binary classification\n",
    "    feature_names=X_train.columns,  # Feature names\n",
    "    class_names=['Class 0', 'Class 1'],  # Class names for binary classification\n",
    "    discretize_continuous=True  # Discretizes continuous features\n",
    ")\n",
    "\n",
    "# Select a random instance from the test set\n",
    "idx = 200  # You can change this index to select a different instance\n",
    "instance = X_test.iloc[idx]  # The input instance\n",
    "true_label = y_test.iloc[idx]\n",
    "\n",
    "print(\"True Label for selected instance:\", true_label)\n",
    "print(\"Instance features:\\n\", instance)\n",
    "\n",
    "# Explain the instance using the LIME explainer\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=instance,  # Instance to explain\n",
    "    predict_fn=predict_proba_wrapper,  # Use the wrapper function here\n",
    "    num_features=10  # Number of features to include in the explanation\n",
    ")\n",
    "\n",
    "# Extract feature contributions from the explanation object\n",
    "feature_importance = exp.as_list()  # Returns a list of (feature, contribution) tuples\n",
    "\n",
    "# Convert the feature importance to a DataFrame for easy visualization\n",
    "lime_df = pd.DataFrame(feature_importance, columns=['Feature', 'Contribution'])\n",
    "\n",
    "# Plot the LIME explanation using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x='Contribution', \n",
    "    y='Feature', \n",
    "    data=lime_df, \n",
    "    palette='viridis', \n",
    "    orient='h'\n",
    ")\n",
    "plt.title(f'LIME Explanation for Instance {idx} (True Label: {true_label})')\n",
    "plt.xlabel('Feature Contribution')\n",
    "plt.ylabel('Feature')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Display the running time\n",
    "print(\"Current time:\", datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
