{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for heartbeat Binary classification with CNN model, mit shifted data\n",
    "\n",
    "We want to load the scaler that we created for mit train set, the mit shift method as transform and the model trained with cnn for binary classification.   \n",
    "So that we can use the pipeline in the product env. \n",
    "\n",
    "If you don't have the input files: run the following notebooks   \n",
    "1. 'preprocessing_mit_binary_shift_minmax_oversampling.ipynb' to generate the preprocessed data for model train and also save the scaler that we are going to use.\n",
    "2. 'modeling_mit_binary_shift_CNN.ipynb' to train the model with the cnn and save the model that we are going to use. \n",
    "3. 'preprocessing_mit_clean.ipynb' to add columns and encode target as binary\n",
    "\n",
    "Input file:   (scaler & model)   \n",
    "mit_binary_minmax_scaler.joblib (saved mit minmax scaler)   \n",
    "model_mit_binary_shift_cnn.h5 (saved binary model with cnn and shift data)  \n",
    "mitbih_test_clean.csv   (raw file with columns added and target encoded to test pipeline)  \n",
    "\n",
    "output file:    \n",
    "mit_binary_classification_pipeline.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local environment\n",
      "Current working directory: g:\\Meine Ablage\\heartbeat-analysis-ai\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "data_path = ''\n",
    "model_output_path = ''\n",
    "# check if the enviorment is Google Colab\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running on Google Colab\")\n",
    "    # Install required libraries\n",
    "    !pip install scikit-learn -q\n",
    "    !pip install pandas -q\n",
    "    !pip install numpy -q\n",
    "    !pip install imbalanced-learn -q\n",
    "    !pip install matplotlib -q\n",
    "    !pip install seaborn -q\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # set the path where the csv file stored in your google drive.\n",
    "    data_path = '/content/drive/MyDrive/heartbeat-deep-model/'\n",
    "    model_path = data_path\n",
    "    pipeline_path = data_path\n",
    "\n",
    "else:\n",
    "    print(\"Running on local environment\")\n",
    "\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current working directory:\", current_path)\n",
    "    data_path = '../data/processed/'\n",
    "    model_path = '../models/'\n",
    "    pipeline_path = '../pipelines/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import joblib\n",
    "\n",
    "scaler_file_name = 'mit_binary_minmax_scaler.joblib'\n",
    "model_file_name = 'model_mit_binary_shift_cnn.h5'\n",
    "mit_test_file = 'mitbih_test_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the transformer \n",
    "def find_top_n_peaks(signal, n=5):\n",
    "    # Find highest peaks\n",
    "    high_peaks, _ = find_peaks(signal)\n",
    "    high_peaks_values = signal[high_peaks]\n",
    "    top_high_peaks = sorted(zip(high_peaks, high_peaks_values), key=lambda x: -x[1])[:n]\n",
    "\n",
    "    # Find lowest peaks \n",
    "    low_peaks, _ = find_peaks(signal * -1) # -1 means invert the signal to find the lowest peaks\n",
    "    low_peaks_values = signal[low_peaks]\n",
    "    top_low_peaks = sorted(zip(low_peaks, low_peaks_values), key=lambda x: x[1])[:n]\n",
    "\n",
    "    return top_high_peaks, top_low_peaks\n",
    "\n",
    "def find_peak_one_row(data) -> int:\n",
    "    ### find the peak which take the whole ecg signal \n",
    "    ### return the index \n",
    "    high_peaks, _ = find_peaks(data)\n",
    "    # as we need about 75 - 125 signal to identify the whole ecg period\n",
    "    # in this case the maximum R wave may appear at first 6-10 , or 8-15\n",
    "    # based on that we can conclude the valid peak may exists in range of [6, 160 ]\n",
    "    # valid_high_peaks = [ value for value in high_peaks if 6<=value<=160]\n",
    "    valid_high_peaks = [ value for value in high_peaks if 15<=value<=150]\n",
    "    high_peaks_values = data[high_peaks]\n",
    "    high_peaks_values = data[ valid_high_peaks if len(valid_high_peaks)> 0 else high_peaks   ]\n",
    "    top_high_peaks = sorted(zip(high_peaks, high_peaks_values), key=lambda x: -x[1])[:1]\n",
    "\n",
    "    return top_high_peaks[0][0]\n",
    "\n",
    "def shift_row(data, center): \n",
    "    peak = find_peak_one_row(data)\n",
    "    target = data[-1]\n",
    "\n",
    "    # Calculate the shift needed to move the highest value to the center\n",
    "    shift = center - peak\n",
    "    \n",
    "    # Create an output array filled with None\n",
    "    shifted_array = [0] * len(data)\n",
    "    \n",
    "    # Shift the elements and handle out-of-bound cases\n",
    "    for i in range(len(data)):\n",
    "        new_index = i + shift\n",
    "        if 0 <= new_index < len(data):  # Ensure new index is within bounds\n",
    "            shifted_array[new_index] = data[i]\n",
    "    shifted_array[-1] = target\n",
    "    return shifted_array\n",
    "    # return pd.Series(shifted_array)\n",
    "\n",
    "def get_shift_dataframe(df, center):\n",
    "    \n",
    "    df_shifted = df.apply( lambda row:  shift_row(row, center), axis=1)\n",
    "\n",
    "    return df_shifted\n",
    "\n",
    "class MitDataShiftTransformer(BaseEstimator, TransformerMixin): \n",
    "    \"\"\"\n",
    "    A transformer to shift mit heartbeat ecg signal, to align R wave peak to a specific position to better predict \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, r_peak_position='87'):\n",
    "        \"\"\"\n",
    "        r_peak_position: default value 87 as we get the average R wave peak at 87 for mit train set. \n",
    "        \"\"\"\n",
    "        self.r_peak_position = r_peak_position\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Nothing to record, as we already get the r_peak_position from the mit train set\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X): \n",
    "        print('X transform shape', X.shape)\n",
    "        X_transformed = np.array( [self._get_shifted_row(row) for row in X])\n",
    "        print('X_transformed', X_transformed.shape)\n",
    "        return X_transformed\n",
    "    \n",
    "    def _get_shifted_row(self, data):\n",
    "        peak = self._find_peak_one_row(data)\n",
    "        # Calculate the shift needed to move the highest value to the center\n",
    "        shift = self.r_peak_position - peak\n",
    "        \n",
    "        # Create an output array filled with None\n",
    "        shifted_array = np.zeros(len(data)) ## [0] * len(data)\n",
    "        \n",
    "        # Shift the elements and handle out-of-bound cases\n",
    "        for i in range(len(data)):\n",
    "            new_index = i + shift\n",
    "            if 0 <= new_index < len(data):  # Ensure new index is within bounds\n",
    "                shifted_array[new_index] = data[i]\n",
    "        return shifted_array\n",
    "        # return pd.Series(shifted_array)\n",
    "        \n",
    "    def _find_peak_one_row(self, data)-> int:\n",
    "         ### find the peak which take the whole ecg signal \n",
    "        ### return the index \n",
    "        high_peaks, _ = find_peaks(data)\n",
    "\n",
    "        # as we need about 75 - 125 signal to identify the whole ecg period\n",
    "        # in this case the maximum R wave may appear at first 6-10 , or 8-15\n",
    "        # based on that we can conclude the valid peak may exists in range of [6, 160 ]\n",
    "        valid_high_peaks = [ value for value in high_peaks if 6<=value<=160]\n",
    "        high_peaks_values = data[high_peaks]\n",
    "        high_peaks_values = data[ valid_high_peaks if len(valid_high_peaks)> 0 else high_peaks   ]\n",
    "        top_high_peaks = sorted(zip(high_peaks, high_peaks_values), key=lambda x: -x[1])[:1]\n",
    "\n",
    "        return top_high_peaks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isabell Gurstein\\anaconda3\\envs\\DataScientestNotebooksEnv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "shift_transform = MitDataShiftTransformer(87) # 87 is the average R peak position for mit train set\n",
    "scaler = joblib.load(data_path + scaler_file_name)\n",
    "\n",
    "# mit_train  = pd.read_csv(data_path+'mit_train_clean.csv')\n",
    "# X_train = mit_train.drop(columns=['target'])\n",
    "# y_train = mit_train['target']\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit_transform(X_train_resampled)\n",
    "\n",
    "model = load_model(model_path + model_file_name)\n",
    "\n",
    "mit_binary_classification_pipeline = Pipeline([\n",
    "    ('shift_transform', shift_transform),\n",
    "    ('scaler', scaler),\n",
    "    ('cnn', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X transform shape (20284, 187)\n",
      "X_transformed (20284, 187)\n",
      "\u001b[1m634/634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Optimal Threshold: 0.12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score       support\n",
      "0              0.956077  0.917872  0.936585  18118.000000\n",
      "1              0.485121  0.647276  0.554589   2166.000000\n",
      "accuracy       0.888977  0.888977  0.888977      0.888977\n",
      "macro avg      0.720599  0.782574  0.745587  20284.000000\n",
      "weighted avg   0.905786  0.888977  0.895794  20284.000000\n"
     ]
    }
   ],
   "source": [
    "# test pipeline\n",
    "\n",
    "mit_test = pd.read_csv(data_path + mit_test_file)\n",
    "# mit_test = pd.read_csv(data_path + 'mitbih_binary_test_shift_minmax_oversampling.csv')\n",
    "\n",
    "X_test_values = mit_test.drop(columns=['target']).values\n",
    "y_test_values = mit_test['target'].values\n",
    "\n",
    "y_predict = mit_binary_classification_pipeline.predict(X_test_values).ravel()\n",
    "\n",
    "# Calculate the optimal threshold\n",
    "fpr, tpr, thresholds = roc_curve(y_test_values, y_predict) # threshold for the decision function to maximize the true positive rate while minimizing the false positive rate\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "y_pred_class = (y_predict >= optimal_threshold).astype(int)\n",
    "\n",
    "# Display classification report\n",
    "report_dict = classification_report(y_test_values, y_pred_class, output_dict=True)\n",
    "print(\"Classification Report:\")\n",
    "print(pd.DataFrame(report_dict).transpose())\n",
    "\n",
    "# format the classification report into table\n",
    "report = classification_report(y_test_values, y_pred_class, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(data_path + 'mit_test_classification_report.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../pipelines/mit_binary_classification_pipeline.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the shift transformer and model \n",
    "# so that the product can load file to make predict. \n",
    "joblib.dump(mit_binary_classification_pipeline,  pipeline_path+'mit_binary_classification_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 2025-02-03 14:51:15.663599\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Display the running time\n",
    "print(\"Current time:\", datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScientestNotebooksEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
