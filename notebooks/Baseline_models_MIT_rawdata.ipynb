{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Models and optimization steps for MIT data\n",
        " (Logistic Regression, Decision Tree, Naive Bayes, Random Forest)\n",
        "\n",
        "as a seperate file we have applied KNN model on MIT data (run the notebook: modeling_mit_knn.ipynb)\n",
        "\n",
        "As we concluded before, for MIT data, we apply the following preprocessing:\n",
        "resampling: Oversampling\n",
        "rescaling: MinMax Scaler\n",
        "\n",
        "If you don't have the original files: run the notebook preprocessing_mit_minmax_oversampling.ipynb\n",
        "\n",
        "Input file: (The preprocessed data)\n",
        "\n",
        "mitbih_train_clean_minmax_oversampling.csv\n",
        "mitbih_test_clean_minmax_oversampling.csv\n",
        "\n",
        "Output:\n",
        "accuracy and classification reports of each model"
      ],
      "metadata": {
        "id": "Gwz-SOX1wMbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "data_path = ''\n",
        "model_output_path = ''\n",
        "# check if the enviorment is Google Colab\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running on Google Colab\")\n",
        "    # Install required libraries\n",
        "    # !pip install scikit-learn -q\n",
        "    # !pip install pandas -q\n",
        "    # !pip install numpy -q\n",
        "    # !pip install imbalanced-learn -q\n",
        "\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # set the path where the csv file stored in your google drive.\n",
        "    data_path = '/content/drive/MyDrive/Heartbeat_Project_me/preprocessed_data/'\n",
        "    model_output_path = '/content/drive/MyDrive/Heartbeat_Project_me/model_output/'\n",
        "\n",
        "else:\n",
        "    print(\"Running on local environment\")\n",
        "\n",
        "    current_path = os.getcwd()\n",
        "    print(\"Current working directory:\", current_path)\n",
        "    data_path = '../data/processed/'\n",
        "    model_output_path = '../models/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjcKZtbJpLIo",
        "outputId": "c069c285-37e0-4023-f6a2-e9e57c9fa9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxLUweCPpEAZ",
        "outputId": "276167f7-44bd-406c-925b-af6ae9856029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9114080063103924\n",
            "Logistic Regression Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95     18118\n",
            "           1       0.73      0.27      0.39      2166\n",
            "\n",
            "    accuracy                           0.91     20284\n",
            "   macro avg       0.83      0.63      0.67     20284\n",
            "weighted avg       0.90      0.91      0.89     20284\n",
            "\n",
            "Decision Tree Accuracy: 0.9631236442516269\n",
            "Decision Tree Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     18118\n",
            "           1       0.84      0.81      0.82      2166\n",
            "\n",
            "    accuracy                           0.96     20284\n",
            "   macro avg       0.91      0.90      0.90     20284\n",
            "weighted avg       0.96      0.96      0.96     20284\n",
            "\n",
            "Naive Bayes Accuracy: 0.8454939854072175\n",
            "Naive Bayes Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91     18118\n",
            "           1       0.31      0.36      0.33      2166\n",
            "\n",
            "    accuracy                           0.85     20284\n",
            "   macro avg       0.62      0.63      0.62     20284\n",
            "weighted avg       0.86      0.85      0.85     20284\n",
            "\n",
            "Random Forest Accuracy: 0.9788010254387695\n",
            "Random Forest Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99     18118\n",
            "           1       0.99      0.81      0.89      2166\n",
            "\n",
            "    accuracy                           0.98     20284\n",
            "   macro avg       0.98      0.91      0.94     20284\n",
            "weighted avg       0.98      0.98      0.98     20284\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "RawFiles = dict({\n",
        "    'train': data_path + 'mitbih_train_clean.csv',\n",
        "    'test': data_path + 'mitbih_test_clean.csv'\n",
        "})\n",
        "\n",
        "\n",
        "OutputFiles = dict({\n",
        "    'model': model_output_path +  'baseline_models_mit_raw.csv',\n",
        "    'Optimization' : model_output_path + 'optimization_baseline_models_mit_raw.csv'\n",
        "})\n",
        "\n",
        "\n",
        "train = pd.read_csv(RawFiles.get('train'),sep=',',header=0)\n",
        "test = pd.read_csv(RawFiles.get('test'),sep=',',header=0)\n",
        "\n",
        "y_train = train['target']\n",
        "X_train = train.drop('target', axis=1)\n",
        "\n",
        "y_test = test['target']\n",
        "X_test = test.drop('target', axis=1)\n",
        "\n",
        "# Baseline model 1: Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=500)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
        "print(\"Logistic Regression Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Baseline model 2: Decision Tree\n",
        "dec_tree = DecisionTreeClassifier()\n",
        "dec_tree.fit(X_train, y_train)\n",
        "y_pred_dec_tree = dec_tree.predict(X_test)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dec_tree))\n",
        "print(\"Decision Tree Report:\\n\", classification_report(y_test, y_pred_dec_tree))\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Baseline model 4: Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Naive Bayes Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Baseline model 5: Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Report:\\n\", classification_report(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Function to evaluate models and store results\n",
        "def evaluate_model(model, X_test, y_test, model_name, results):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Classification Report:\\n {classification_report(y_test, y_pred)}\")\n",
        "    results[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': report['weighted avg']['precision'],\n",
        "        'recall': report['weighted avg']['recall'],\n",
        "        'f1-score': report['weighted avg']['f1-score']\n",
        "    }\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Baseline model 1: Logistic Regression\n",
        "evaluate_model(log_reg, X_test, y_test, \"Logistic Regression\", results)\n",
        "\n",
        "# Baseline model 2: Decision Tree\n",
        "evaluate_model(dec_tree, X_test, y_test, \"Decision Tree\", results)\n",
        "\n",
        "# Baseline model 3: Support Vector Machine\n",
        "# evaluate_model(svm, X_test, y_test, \"Support Vector Machine\", results)\n",
        "\n",
        "# Baseline model 4: Naive Bayes\n",
        "evaluate_model(nb, X_test, y_test, \"Naive Bayes\", results)\n",
        "\n",
        "# Baseline model 5: Random Forest\n",
        "evaluate_model(rf, X_test, y_test, \"Random Forest\", results)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparison of Baseline Models:\")\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z0BP9ugphem",
        "outputId": "5fac9820-2d0f-451f-8282-93b959f05e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.9114080063103924\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95     18118\n",
            "           1       0.73      0.27      0.39      2166\n",
            "\n",
            "    accuracy                           0.91     20284\n",
            "   macro avg       0.83      0.63      0.67     20284\n",
            "weighted avg       0.90      0.91      0.89     20284\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.9631236442516269\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     18118\n",
            "           1       0.84      0.81      0.82      2166\n",
            "\n",
            "    accuracy                           0.96     20284\n",
            "   macro avg       0.91      0.90      0.90     20284\n",
            "weighted avg       0.96      0.96      0.96     20284\n",
            "\n",
            "Naive Bayes:\n",
            "Accuracy: 0.8454939854072175\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91     18118\n",
            "           1       0.31      0.36      0.33      2166\n",
            "\n",
            "    accuracy                           0.85     20284\n",
            "   macro avg       0.62      0.63      0.62     20284\n",
            "weighted avg       0.86      0.85      0.85     20284\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.9788010254387695\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99     18118\n",
            "           1       0.99      0.81      0.89      2166\n",
            "\n",
            "    accuracy                           0.98     20284\n",
            "   macro avg       0.98      0.91      0.94     20284\n",
            "weighted avg       0.98      0.98      0.98     20284\n",
            "\n",
            "\n",
            "Comparison of Baseline Models:\n",
            "                     accuracy  precision    recall  f1-score\n",
            "Logistic Regression  0.911408   0.898769  0.911408  0.892554\n",
            "Decision Tree        0.963124   0.962706  0.963124  0.962895\n",
            "Naive Bayes          0.845494   0.856441  0.845494  0.850672\n",
            "Random Forest        0.978801   0.978985  0.978801  0.977876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Baseline model 2: KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn_model = knn_model.predict(X_test)\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn_model))\n",
        "print(\"KNN Report:\\n\", classification_report(y_test, y_pred_knn_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BINpBO_d18i-",
        "outputId": "c26b6497-17e2-4a17-fb96-78366d02984e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.9789489252612897\n",
            "KNN Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     18118\n",
            "           1       0.95      0.85      0.90      2166\n",
            "\n",
            "    accuracy                           0.98     20284\n",
            "   macro avg       0.97      0.92      0.94     20284\n",
            "weighted avg       0.98      0.98      0.98     20284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "results = {}\n",
        "# Hyperparameter tuning for Logistic Regression\n",
        "param_grid_log_reg = {'C': [0.1, 1, 10, 100]}\n",
        "grid_log_reg = GridSearchCV(LogisticRegression(), param_grid_log_reg, cv=3, n_jobs=-1)\n",
        "grid_log_reg.fit(X_train, y_train)\n",
        "best_log_reg = grid_log_reg.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_log_reg.best_params_}\")\n",
        "evaluate_model(best_log_reg, X_test, y_test, \"Tuned Logistic Regression\", results)\n",
        "\n",
        "\n",
        "# Hyperparameter tuning for Decision Tree\n",
        "param_grid_dec_tree = {'max_depth': [3, 5, 7, 10]}\n",
        "grid_dec_tree = GridSearchCV(DecisionTreeClassifier(), param_grid_dec_tree, cv=3, n_jobs=-1)\n",
        "grid_dec_tree.fit(X_train, y_train)\n",
        "best_dec_tree = grid_dec_tree.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_dec_tree.best_params_}\")\n",
        "evaluate_model(best_dec_tree, X_test, y_test, \"Tuned Decision Tree\", results)\n",
        "\n",
        "# # Hyperparameter tuning for Support Vector Machine\n",
        "# param_grid_svm = {'C': [0.1, 10, 100], 'kernel': ['linear']}\n",
        "# grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=3, n_jobs=-1)\n",
        "# grid_svm.fit(X_train, y_train)\n",
        "# evaluate_model(grid_svm, X_test, y_test, \"Tuned SVM\", results)\n",
        "\n",
        "# Hyperparameter tuning for Naive Bayes\n",
        "param_grid_nb = {'var_smoothing': [1e-9, 1e-8, 1e-7]}\n",
        "grid_nb = GridSearchCV(GaussianNB(), param_grid_nb, cv=3, n_jobs=-1)\n",
        "grid_nb.fit(X_train, y_train)\n",
        "best_nb = grid_nb.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_nb.best_params_}\")\n",
        "evaluate_model(best_nb, X_test, y_test, \"Tuned Naive Bayes\", results)\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "best_rf = grid_rf.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_rf.best_params_}\")\n",
        "evaluate_model(best_rf, X_test, y_test, \"Tuned Random Forest\", results)\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df_grid = pd.DataFrame(results).T\n",
        "print(\"\\nComparison of Hyperparameter Tuned Models:\")\n",
        "print(results_df_grid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A77OKJT1pieZ",
        "outputId": "a00825d2-01be-4f29-9e3b-948a65c74015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Logistic Regression: {'C': 100}\n",
            "Tuned Logistic Regression:\n",
            "Accuracy: 0.8067935318477618\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.81      0.88     18118\n",
            "           1       0.33      0.77      0.46      2166\n",
            "\n",
            "    accuracy                           0.81     20284\n",
            "   macro avg       0.65      0.79      0.67     20284\n",
            "weighted avg       0.90      0.81      0.84     20284\n",
            "\n",
            "Best parameters for Logistic Regression: {'max_depth': 10}\n",
            "Tuned Decision Tree:\n",
            "Accuracy: 0.9413330704003156\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97     18118\n",
            "           1       0.69      0.83      0.75      2166\n",
            "\n",
            "    accuracy                           0.94     20284\n",
            "   macro avg       0.83      0.89      0.86     20284\n",
            "weighted avg       0.95      0.94      0.94     20284\n",
            "\n",
            "Best parameters for Logistic Regression: {'var_smoothing': 1e-09}\n",
            "Tuned Naive Bayes:\n",
            "Accuracy: 0.8423880891342931\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91     18118\n",
            "           1       0.30      0.37      0.33      2166\n",
            "\n",
            "    accuracy                           0.84     20284\n",
            "   macro avg       0.61      0.63      0.62     20284\n",
            "weighted avg       0.86      0.84      0.85     20284\n",
            "\n",
            "Best parameters for Logistic Regression: {'max_depth': None, 'n_estimators': 200}\n",
            "Tuned Random Forest:\n",
            "Accuracy: 0.9816111220666536\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99     18118\n",
            "           1       0.98      0.84      0.91      2166\n",
            "\n",
            "    accuracy                           0.98     20284\n",
            "   macro avg       0.98      0.92      0.95     20284\n",
            "weighted avg       0.98      0.98      0.98     20284\n",
            "\n",
            "\n",
            "Comparison of Hyperparameter Tuned Models:\n",
            "                           accuracy  precision    recall  f1-score\n",
            "Tuned Logistic Regression  0.806794   0.898507  0.806794  0.837171\n",
            "Tuned Decision Tree        0.941333   0.947956  0.941333  0.943762\n",
            "Tuned Naive Bayes          0.842388   0.856568  0.842388  0.849003\n",
            "Tuned Random Forest        0.981611   0.981588  0.981611  0.981005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame as a CSV file\n",
        "results_df.to_csv(OutputFiles['model'], index=False)\n",
        "print(f\"DataFrame saved as CSV file at: {OutputFiles['model']}\")\n",
        "\n",
        "results_df_grid.to_csv(OutputFiles['Optimization'], index=False)\n",
        "print(f\"DataFrame saved as CSV file at: {OutputFiles['Optimization']}\")"
      ],
      "metadata": {
        "id": "Dtr70YA7STfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502bdf60-2c3c-4d9d-eb25-fc6760f4bcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as CSV file at: /content/drive/MyDrive/Heartbeat_Project_me/model_output/baseline_models_mit.csv\n",
            "DataFrame saved as CSV file at: /content/drive/MyDrive/Heartbeat_Project_me/model_output/optimization_baseline_models_mit.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "# Display the running time\n",
        "print(\"Current time:\", datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0GkxIW8s5GQ",
        "outputId": "6d590f19-4382-4af2-acb7-64266e06bdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current time: 2024-11-06 13:38:41.831722\n"
          ]
        }
      ]
    }
  ]
}