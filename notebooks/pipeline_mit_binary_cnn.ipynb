{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for heartbeat Binary classification with CNN model, mit shifted data\n",
    "\n",
    "We want to load the scaler that we created for mit train set, the mit shift method as transform and the model trained with cnn for binary classification.   \n",
    "So that we can use the pipeline in the product env. \n",
    "\n",
    "If you don't have the input files: run the following notebooks   \n",
    "1. 'preprocessing_mit_binary_shift_minmax_oversampling.ipynb' to generate the preprocessed data for model train and also save the scaler that we are going to use.\n",
    "2. 'modeling_mit_binary_shift_CNN.ipynb' to train the model with the cnn and save the model that we are going to use. \n",
    "3. 'preprocessing_mit_clean.ipynb' to add columns and encode target as binary\n",
    "\n",
    "Input file:   (scaler & model)   \n",
    "mit_binary_minmax_scaler.joblib (saved mit minmax scaler)   \n",
    "model_mit_binary_shift_cnn.h5 (saved binary model with cnn and shift data)  \n",
    "mitbih_test_clean.csv   (raw file with columns added and target encoded to test pipeline)  \n",
    "\n",
    "output file:    \n",
    "mit_binary_classification_pipeline.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local environment\n",
      "Current working directory: /Users/pingyuan/Documents/codeself/heartbeat-analysis-ai/notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "data_path = ''\n",
    "model_output_path = ''\n",
    "# check if the enviorment is Google Colab\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running on Google Colab\")\n",
    "    # Install required libraries\n",
    "    !pip install scikit-learn -q\n",
    "    !pip install pandas -q\n",
    "    !pip install numpy -q\n",
    "    !pip install imbalanced-learn -q\n",
    "    !pip install matplotlib -q\n",
    "    !pip install seaborn -q\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # set the path where the csv file stored in your google drive.\n",
    "    data_path = '/content/drive/MyDrive/heartbeat-deep-model/'\n",
    "    model_path = data_path\n",
    "    pipeline_path = data_path\n",
    "\n",
    "else:\n",
    "    print(\"Running on local environment\")\n",
    "\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current working directory:\", current_path)\n",
    "    data_path = '../data/processed/'\n",
    "    model_path = '../models/'\n",
    "    pipeline_path = '../pipelines/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import joblib\n",
    "\n",
    "scaler_file_name = 'mit_binary_minmax_scaler.joblib'\n",
    "model_file_name = 'model_mit_binary_shift_cnn.h5'\n",
    "mit_test_file = 'mit_test_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the transformer \n",
    "def find_top_n_peaks(signal, n=5):\n",
    "    # Find highest peaks\n",
    "    high_peaks, _ = find_peaks(signal)\n",
    "    high_peaks_values = signal[high_peaks]\n",
    "    top_high_peaks = sorted(zip(high_peaks, high_peaks_values), key=lambda x: -x[1])[:n]\n",
    "\n",
    "    # Find lowest peaks \n",
    "    low_peaks, _ = find_peaks(signal * -1) # -1 means invert the signal to find the lowest peaks\n",
    "    low_peaks_values = signal[low_peaks]\n",
    "    top_low_peaks = sorted(zip(low_peaks, low_peaks_values), key=lambda x: x[1])[:n]\n",
    "\n",
    "    return top_high_peaks, top_low_peaks\n",
    "\n",
    "def find_peak_one_row(data) -> int:\n",
    "    ### find the peak which take the whole ecg signal \n",
    "    ### return the index \n",
    "    high_peaks, _ = find_peaks(data)\n",
    "    # as we need about 75 - 125 signal to identify the whole ecg period\n",
    "    # in this case the maximum R wave may appear at first 6-10 , or 8-15\n",
    "    # based on that we can conclude the valid peak may exists in range of [6, 160 ]\n",
    "    # valid_high_peaks = [ value for value in high_peaks if 6<=value<=160]\n",
    "    valid_high_peaks = [ value for value in high_peaks if 15<=value<=150]\n",
    "    high_peaks_values = data[high_peaks]\n",
    "    high_peaks_values = data[ valid_high_peaks if len(valid_high_peaks)> 0 else high_peaks   ]\n",
    "    top_high_peaks = sorted(zip(high_peaks, high_peaks_values), key=lambda x: -x[1])[:1]\n",
    "\n",
    "    return top_high_peaks[0][0]\n",
    "\n",
    "def shift_row(data, center): \n",
    "    peak = find_peak_one_row(data)\n",
    "    target = data[-1]\n",
    "\n",
    "    # Calculate the shift needed to move the highest value to the center\n",
    "    shift = center - peak\n",
    "    \n",
    "    # Create an output array filled with None\n",
    "    shifted_array = [0] * len(data)\n",
    "    \n",
    "    # Shift the elements and handle out-of-bound cases\n",
    "    for i in range(len(data)):\n",
    "        new_index = i + shift\n",
    "        if 0 <= new_index < len(data):  # Ensure new index is within bounds\n",
    "            shifted_array[new_index] = data[i]\n",
    "    shifted_array[-1] = target\n",
    "    return shifted_array\n",
    "    # return pd.Series(shifted_array)\n",
    "\n",
    "def get_shift_dataframe(df, center):\n",
    "    \n",
    "    df_shifted = df.apply( lambda row:  shift_row(row, center), axis=1)\n",
    "\n",
    "    return df_shifted\n",
    "\n",
    "class MitDataShiftTransformer(BaseEstimator, TransformerMixin): \n",
    "    \"\"\"\n",
    "    A transformer to shift mit heartbeat ecg signal, to align R wave peak to a specific position to better predict \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, r_peak_position='87'):\n",
    "        \"\"\"\n",
    "        r_peak_position: default value 87 as we get the average R wave peak at 87 for mit train set. \n",
    "        \"\"\"\n",
    "        self.r_peak_position = r_peak_position\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Nothing to record, as we already get the r_peak_position from the mit train set\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X): \n",
    "        print('X transform shape', X.shape)\n",
    "        X_transformed = np.array( [self._get_shifted_row(row) for row in X])\n",
    "        print('X_transformed', X_transformed.shape)\n",
    "        return X_transformed\n",
    "    \n",
    "    def _get_shifted_row(self, data):\n",
    "        peak = self._find_peak_one_row(data)\n",
    "        # Calculate the shift needed to move the highest value to the center\n",
    "        shift = self.r_peak_position - peak\n",
    "        \n",
    "        # Create an output array filled with None\n",
    "        shifted_array = np.zeros(len(data)) ## [0] * len(data)\n",
    "        \n",
    "        # Shift the elements and handle out-of-bound cases\n",
    "        for i in range(len(data)):\n",
    "            new_index = i + shift\n",
    "            if 0 <= new_index < len(data):  # Ensure new index is within bounds\n",
    "                shifted_array[new_index] = data[i]\n",
    "        return shifted_array\n",
    "        # return pd.Series(shifted_array)\n",
    "        \n",
    "    def _find_peak_one_row(self, data)-> int:\n",
    "         ### find the peak which take the whole ecg signal \n",
    "        ### return the index \n",
    "        high_peaks, _ = find_peaks(data)\n",
    "\n",
    "        # as we need about 75 - 125 signal to identify the whole ecg period\n",
    "        # in this case the maximum R wave may appear at first 6-10 , or 8-15\n",
    "        # based on that we can conclude the valid peak may exists in range of [6, 160 ]\n",
    "        valid_high_peaks = [ value for value in high_peaks if 6<=value<=160]\n",
    "        high_peaks_values = data[high_peaks]\n",
    "        high_peaks_values = data[ valid_high_peaks if len(valid_high_peaks)> 0 else high_peaks   ]\n",
    "        top_high_peaks = sorted(zip(high_peaks, high_peaks_values), key=lambda x: -x[1])[:1]\n",
    "\n",
    "        return top_high_peaks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "shift_transform = MitDataShiftTransformer(87)\n",
    "scaler = joblib.load(data_path + scaler_file_name)\n",
    "\n",
    "# mit_train  = pd.read_csv(data_path+'mit_train_clean.csv')\n",
    "# X_train = mit_train.drop(columns=['target'])\n",
    "# y_train = mit_train['target']\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit_transform(X_train_resampled)\n",
    "\n",
    "model = load_model(model_path + model_file_name)\n",
    "\n",
    "mit_binary_classification_pipeline = Pipeline([\n",
    "    ('shift_transform', shift_transform),\n",
    "    ('scaler', scaler),\n",
    "    ('cnn', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform <class 'numpy.ndarray'>\n",
      "X transform shape (20284, 187)\n",
      "X_transformed (20284, 187)\n",
      "plot transform image\n",
      "634/634 [==============================] - 2s 3ms/step\n",
      "Optimal Threshold: 0.06\n",
      "0    16618\n",
      "1     3666\n",
      "Name: count, dtype: int64\n",
      "[0 0 0 ... 1 1 1]\n",
      "(array([0, 1]), array([18118,  2166]))\n",
      "classification report\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.97      0.89      0.92     18118\\n           1       0.44      0.74      0.55      2166\\n\\n    accuracy                           0.87     20284\\n   macro avg       0.70      0.82      0.74     20284\\nweighted avg       0.91      0.87      0.89     20284\\n'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test pipeline\n",
    "\n",
    "mit_test = pd.read_csv(data_path + mit_test_file)\n",
    "# mit_test = pd.read_csv(data_path + 'mitbih_binary_test_shift_minmax_oversampling.csv')\n",
    "\n",
    "X_test_values = mit_test.drop(columns=['target']).values\n",
    "y_test_values = mit_test['target'].values\n",
    "\n",
    "y_predict = mit_binary_classification_pipeline.predict(X_test_values).ravel()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_values, y_predict)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.2f}\")\n",
    "\n",
    "y_pred_class = (y_predict >= optimal_threshold).astype(int)\n",
    "print('classification report')\n",
    "classification_report(y_test_values, y_pred_class)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../pipeline/mit_binary_classification_pipeline.joblib']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the shift transformer and model \n",
    "# so that the product can load file to make predict. \n",
    "joblib.dump(mit_binary_classification_pipeline,  pipeline_path+'mit_binary_classification_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Display the running time\n",
    "print(\"Current time:\", datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
