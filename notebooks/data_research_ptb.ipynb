{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check enviroment**\n",
    "\n",
    "Set data_path to make notebooks works well both on local and google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "data_path = ''\n",
    "# Check if the environment is Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running on Google Colab\")\n",
    "    # Install required libraries\n",
    "    !pip install tensorflow -q\n",
    "    !pip install keras -q\n",
    "    !pip install scikit-learn -q\n",
    "    !pip install pandas -q\n",
    "    !pip install numpy -q\n",
    "    !pip install matplotlib -q\n",
    "    !pip install umap-learn -q\n",
    "    \n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # set the path where the csv file stored in your own google drive. \n",
    "    data_path = '/content/drive/MyDrive/Heartbeat_Project/'\n",
    "    \n",
    "else:\n",
    "    print(\"Running on local environment\")\n",
    "\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current working directory:\", current_path)\n",
    "    data_path = '../data/raw/'\n",
    "\n",
    "Path = dict({\n",
    "    'ptbdb_normal': data_path +  'ptbdb_normal.csv',\n",
    "    'ptbdb_abnormal':  data_path + 'ptbdb_abnormal.csv',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verify installation and import libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import Isomap\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumnsToDataframe(df):\n",
    "    \"\"\"\n",
    "    As the dataset is composed with 188 columns with the 188th columns as the category values,\n",
    "    so we give the last column the name 'target', others named with 'c_182'\n",
    "    \"\"\"\n",
    "    num_columns= df.shape[1]\n",
    "    feature_col_name = ['c_' + str(i) for i in range(0, num_columns - 1)]\n",
    "    df_columns = feature_col_name + ['target']\n",
    "    df.columns = df_columns\n",
    "    return df\n",
    "\n",
    "def convertColumnAsInt(df, column):\n",
    "    \"\"\"\n",
    "    As the category value is in float type. We want to get the int to identify the category.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].astype(int)\n",
    "    return df\n",
    "\n",
    "def getBarChartFromCategoryValueCounts(category_value_counts):\n",
    "    \"\"\"\n",
    "    We call the plot over the pandas series object to plot the category count values\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_chart = category_value_counts.plot(kind='bar')\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.xticks(rotation=360)\n",
    "    for i in bar_chart.containers:\n",
    "        bar_chart.bar_label(i, label_type='edge')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showTop10DataInChart(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    xDataAxis = list(range(0, df.shape[1]))\n",
    "    yDataRows = list(df.values[1: 10])\n",
    "    for y in yDataRows:\n",
    "        plt.plot(xDataAxis, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_normal = pd.read_csv(Path.get('ptbdb_normal'), header=None ) \n",
    "ptbdb_normal_with_columns = addColumnsToDataframe(ptbdb_normal) # add columns to the dataframe\n",
    "ptbdb_normal_with_columns = convertColumnAsInt(ptbdb_normal_with_columns, 'target') # convert the target column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_normal_with_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_abnormal = pd.read_csv(Path.get('ptbdb_abnormal'), header=None ) \n",
    "ptbdb_abnormal_with_columns = addColumnsToDataframe(ptbdb_abnormal) # add columns to the dataframe\n",
    "ptbdb_abnormal_with_columns = convertColumnAsInt(ptbdb_abnormal_with_columns, 'target') # convert the target column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_abnormal_with_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge normal and abnomal data to one dataset and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the datasets\n",
    "ptbdb = pd.concat([ptbdb_abnormal_with_columns, ptbdb_normal_with_columns], ignore_index=True) # ingore the index to make the index continuous\n",
    "#Shuffle the dataset\n",
    "ptbdb = ptbdb.sample(frac=1).reset_index(drop=True)\n",
    "ptbdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training (80%) and testing (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "ptbdb_train, ptbdb_test = train_test_split(ptbdb, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train:\n",
    "print(ptbdb_train.shape)\n",
    "print(\"The train data has 11.641 and 188 columns.\")\n",
    "\n",
    "#test:\n",
    "print(ptbdb_test.shape)\n",
    "print(\"The test data has 2.911 and 188 columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ptbdb_train[\"target\"])\n",
    "print(ptbdb_test[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ptbdb_train.dtypes)\n",
    "print(ptbdb_test.dtypes)\n",
    "print(\"The features are numeric. All columns have the type float64, while the target column is int32.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ptbdb_test.info(show_counts=True), end=\"\\n\\n\")\n",
    "print(\"Size of the DataFrame\", ptbdb_test.shape, end='\\n\\n')\n",
    "\n",
    "print(ptbdb_train.info(show_counts=True), end=\"\\n\\n\")\n",
    "print(\"Size of the DataFrame\", ptbdb_train.shape, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_rows_duplicated = ptbdb_train.duplicated().sum()\n",
    "print(\"Number of rows duplicated :\", nb_rows_duplicated)\n",
    "\n",
    "nb_rows_duplicated = ptbdb_test.duplicated().sum()\n",
    "print(\"Number of rows duplicated :\", nb_rows_duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the training set\n",
    "ptbdb_train = ptbdb_train.drop_duplicates()\n",
    "\n",
    "# Remove duplicates from the testing set\n",
    "ptbdb_test = ptbdb_test.drop_duplicates()\n",
    "\n",
    "# Verify the removal by checking the number of duplicated rows again\n",
    "nb_rows_duplicated_train = ptbdb_train.duplicated().sum()\n",
    "print(\"Number of rows duplicated in train set after removal:\", nb_rows_duplicated_train)\n",
    "\n",
    "nb_rows_duplicated_test = ptbdb_test.duplicated().sum()\n",
    "print(\"Number of rows duplicated in test set after removal:\", nb_rows_duplicated_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in train:\", ptbdb_train.isnull().sum())\n",
    "print(\"Missing values in test:\", ptbdb_test.isnull().sum())\n",
    "print(\"The data has no missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbdb_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping dictionary\n",
    "class_mapping = {\n",
    "    1: 'Normal',\n",
    "    0: 'Abnormal'\n",
    "}\n",
    "\n",
    "# Define custom colors for each category\n",
    "color_mapping = {\n",
    "    0: 'green',    # Normal beat\n",
    "    1: 'red',      # Abnormal beat \n",
    "}\n",
    "\n",
    "classes_to_plot = [0, 1]\n",
    "\n",
    "# Calculate value counts based on mapped class names\n",
    "value_counts_series_train = ptbdb_train['target'].map(class_mapping).value_counts()\n",
    "# Calculate value counts based on mapped class names\n",
    "value_counts_series_test = ptbdb_test['target'].map(class_mapping).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Dataset Class Distribution:\")\n",
    "print(value_counts_series_train)\n",
    "\n",
    "print(\"\\nTesting Dataset Class Distribution:\")\n",
    "print(value_counts_series_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barplots and Piecharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar chart for the training dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_chart_train = value_counts_series_train.plot(kind='bar', color=color_mapping.values())\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Target Categories (Training Dataset)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add labels to the bars in the training set\n",
    "for container in bar_chart_train.containers:\n",
    "    plt.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for the training dataset\n",
    "plt.figure(figsize=(8, 8))  # Set figure size\n",
    "value_counts_series_train.plot(kind='pie', autopct='%1.1f%%', colors=color_mapping.values(), startangle=90)\n",
    "plt.ylabel('')  # Remove the y-label\n",
    "plt.title('Target Categories (Training Dataset) - Pie Chart')\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for the testing dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_chart_test = value_counts_series_test.plot(kind='bar', color=color_mapping.values())\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Target Categories (Testing Dataset)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add labels to the bars in the testing set\n",
    "for container in bar_chart_test.containers:\n",
    "    plt.bar_label(container, label_type='edge')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for the testing dataset\n",
    "plt.figure(figsize=(8, 8))  # Set figure size\n",
    "value_counts_series_test.plot(kind='pie', autopct='%1.1f%%', colors=color_mapping.values(), startangle=90)\n",
    "plt.ylabel('')  # Remove the y-label\n",
    "plt.title('Target Categories (Testing Dataset) - Pie Chart')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of each class once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot overlay of ECG signals from both datasets for a single class\n",
    "def plot_overlay_ecg_signals(df, label, color, dataset_label): # Define a function to plot overlay of ECG signals for a single class from both datasets\n",
    "    \"\"\"\n",
    "    Plot overlay of ECG signals for a single class from both datasets.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing ECG signals and target labels\n",
    "    label (str or int): Class label to plot\n",
    "    color (str): Color for the plot\n",
    "    dataset_label (str): Label for the dataset (e.g., 'Training', 'Testing')\n",
    "    \"\"\"\n",
    "\n",
    "    # Map the descriptive label to the corresponding class label\n",
    "    if isinstance(label, str):\n",
    "        class_label = [k for k, v in class_mapping.items() if v == label][0] # Get the class label for the specified class name\n",
    "    else:\n",
    "        class_label = label # Use the specified class label\n",
    "    \n",
    "    # Extract data rows for the specified class label\n",
    "    class_data = df[df['target'] == class_label]\n",
    "\n",
    "    # Check if there is any data for the specified class label\n",
    "    if class_data.empty:\n",
    "        print(f\"No data found for class {class_mapping[class_label]}\")\n",
    "        return\n",
    "    \n",
    "    # Extract a sample data row (first row) for the specified class label\n",
    "    sample_data = class_data.iloc[0]\n",
    "\n",
    "    # Plot the sample ECG signal, excluding the 'target' column\n",
    "    plt.plot(sample_data[:-1], label=f'{dataset_label}: {class_mapping[class_label]}', color=color)\n",
    "\n",
    "    plt.title(f\"Overlay of ECG Signals - {dataset_label}\")\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])  # Remove x-axis ticks and labels\n",
    "    plt.legend()\n",
    "\n",
    "# List of classes to plot\n",
    "classes_to_plot = ['Normal', 'Abnormal']\n",
    "\n",
    "# Colors for each class\n",
    "colors = ['green','red']\n",
    "\n",
    "# Plotting overlay for each class in both datasets\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting for training dataset\n",
    "for label, color in zip(classes_to_plot, colors):\n",
    "    plot_overlay_ecg_signals(ptbdb_train, label, color, 'Training')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting for testing dataset\n",
    "for label, color in zip(classes_to_plot, colors):\n",
    "    plot_overlay_ecg_signals(ptbdb_test, label, color, 'Testing')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(class_name, min_val=5, size=70, title=''):\n",
    "    # Map the descriptive label to the corresponding class label\n",
    "    if isinstance(class_name, str):\n",
    "        class_label = [k for k, v in class_mapping.items() if v == class_name][0]  # Convert class name to class label\n",
    "    else:\n",
    "        class_label = class_name  # Use the specified class label directly if it's already a number\n",
    "    \n",
    "    # Filter the dataset based on the class_label\n",
    "    img = ptbdb_train.loc[ptbdb_train['target'] == class_label].iloc[:, min_val:size]\n",
    "    \n",
    "    # Flatten the array\n",
    "    img_flatten = img.values.flatten()\n",
    "    \n",
    "    # Generate corresponding x-values for the histogram\n",
    "    x_values = np.tile(np.arange(min_val, size), img.shape[0])\n",
    "    \n",
    "    # Ensure that the lengths match for histogram plotting\n",
    "    assert len(x_values) == len(img_flatten), \"Mismatch in lengths of x-values and flattened image values.\"\n",
    "    \n",
    "    # Create the 2D histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist2d(x_values, img_flatten, bins=(80, 80), cmap=plt.cm.jet)\n",
    "    plt.colorbar()  # Add a color bar to indicate the intensity of values\n",
    "    plt.title('2D Histogram - ' + title)\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Feature Values')\n",
    "    plt.show()\n",
    "\n",
    "# Plot for Normal Heart Beat\n",
    "plot_hist('Normal', title='Normal Heart Beat')\n",
    "\n",
    "# Plot for Abnormal Heart Beat\n",
    "plot_hist('Abnormal', title='Abnormal Heart Beat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Functions for training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to apply PCA\n",
    "def apply_pca_to_dataset(df, n_components=2):\n",
    "    X = df.drop('target', axis=1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    components = pca.fit_transform(X)\n",
    "    df_pca = pd.DataFrame(data=components, columns=[f'Principal Component {i+1}' for i in range(n_components)])\n",
    "    df_pca['target'] = df['target']\n",
    "    return df_pca, pca\n",
    "\n",
    "# Define the function to plot PCA results (2D)\n",
    "def plot_pca_results(df_pca, title='PCA of Dataset'):\n",
    "    # Define custom colors and labels for each category\n",
    "    color_mapping = {0: 'red', 1: 'green'}\n",
    "    label_mapping = {0: 'Abnormal', 1: 'Normal'}\n",
    "    \n",
    "    # Map the target to the corresponding colors and labels\n",
    "    df_pca['color'] = df_pca['target'].map(color_mapping)\n",
    "    df_pca['label'] = df_pca['target'].map(label_mapping)\n",
    "\n",
    "    # Create a scatter plot for the PCA results\n",
    "    fig = px.scatter(df_pca, x='Principal Component 1', y='Principal Component 2', color='label',\n",
    "                     color_discrete_map={'Normal': 'green', 'Abnormal': 'red'},\n",
    "                     title=title, labels={'label': 'Class'}, opacity=0.5)\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    fig.show()\n",
    "\n",
    "# Define the function to create a Scree plot\n",
    "def create_scree_plot(pca, title='Scree Plot'):\n",
    "    explained_var_ratio = pca.explained_variance_ratio_\n",
    "    components = np.arange(len(explained_var_ratio)) + 1\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(components, explained_var_ratio, 'o-', linewidth=2, color='blue')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Variance Explained (%)')\n",
    "    plt.xticks(components)\n",
    "    plt.show()\n",
    "\n",
    "# Apply PCA to the training dataset for 10 components to create the Scree plot\n",
    "df_pca_train, pca_train = apply_pca_to_dataset(ptbdb_train, n_components=10)\n",
    "create_scree_plot(pca_train, title='Scree Plot for Training Data')\n",
    "\n",
    "# Apply PCA to the training dataset for 2 components and plot the 2D PCA results\n",
    "df_pca_train, pca_train = apply_pca_to_dataset(ptbdb_train, n_components=2)\n",
    "plot_pca_results(df_pca_train, title='PCA of Heartbeat Dataset (2D) - Training Data')\n",
    "\n",
    "# Apply PCA to the training dataset for 3 components and plot the 3D PCA results\n",
    "df_pca_train, pca_train = apply_pca_to_dataset(ptbdb_train, n_components=3)\n",
    "df_pca_train['color'] = df_pca_train['target'].map({0: 'red', 1: 'green'})\n",
    "df_pca_train['label'] = df_pca_train['target'].map({0: 'Abnormal', 1: 'Normal'})\n",
    "\n",
    "fig = px.scatter_3d(df_pca_train, x='Principal Component 1', y='Principal Component 2', z='Principal Component 3',\n",
    "                    color='label',\n",
    "                    color_discrete_map={'Normal': 'green', 'Abnormal': 'red'},\n",
    "                    title='3D PCA of Heartbeat Dataset - Training Data',\n",
    "                    labels={'label': 'Class'}, opacity=0.5)\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.show()\n",
    "\n",
    "# Apply PCA to the test dataset for 10 components to create the Scree plot\n",
    "df_pca_test, pca_test = apply_pca_to_dataset(ptbdb_test, n_components=10)\n",
    "create_scree_plot(pca_test, title='Scree Plot for Test Data')\n",
    "\n",
    "# Apply PCA to the test dataset for 2 components and plot the 2D PCA results\n",
    "df_pca_test, pca_test = apply_pca_to_dataset(ptbdb_test, n_components=2)\n",
    "plot_pca_results(df_pca_test, title='PCA of Heartbeat Dataset (2D) - Test Data')\n",
    "\n",
    "# Apply PCA to the test dataset for 3 components and plot the 3D PCA results\n",
    "df_pca_test, pca_test = apply_pca_to_dataset(ptbdb_test, n_components=3)\n",
    "df_pca_test['color'] = df_pca_test['target'].map({0: 'red', 1: 'green'})\n",
    "df_pca_test['label'] = df_pca_test['target'].map({0: 'Abnormal', 1: 'Normal'})\n",
    "\n",
    "fig = px.scatter_3d(df_pca_test, x='Principal Component 1', y='Principal Component 2', z='Principal Component 3',\n",
    "                    color='label',\n",
    "                    color_discrete_map={'Normal': 'green', 'Abnormal': 'red'},\n",
    "                    title='3D PCA of Heartbeat Dataset - Test Data',\n",
    "                    labels={'label': 'Class'}, opacity=0.5)\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the loadings to determine which variables are most significant in each principal component in training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "df_pca, pca = apply_pca_to_dataset(ptbdb_train, n_components=5)\n",
    "\n",
    "loadings = pca.components_ # Get the loadings for the principal components (eigenvectors)\n",
    "\n",
    "for i, component in enumerate(loadings):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "    plt.bar(x=range(len(component)), height=component)\n",
    "\n",
    "\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Loading')\n",
    "    plt.title(f'Loadings for Principal Component {i+1}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df_pca, pca = apply_pca_to_dataset(ptbdb_test, n_components=5)\n",
    "\n",
    "\n",
    "loadings = pca.components_\n",
    "\n",
    "\n",
    "for i, component in enumerate(loadings):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "    plt.bar(x=range(len(component)), height=component)\n",
    "\n",
    "\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Loading')\n",
    "    plt.title(f'Loadings for Principal Component {i+1}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify significant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway, kruskal\n",
    "# Separate features and labels\n",
    "features = ptbdb_train.iloc[:, :-1]\n",
    "labels = ptbdb_train['target']\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for i in range(features.shape[1]):\n",
    "\n",
    "    class_groups = [features[labels == label].iloc[:, i] for label in class_mapping.values()]\n",
    "\n",
    "    # If not normally distributed, use Kruskal-Wallis H-test\n",
    "    h_stat, p_val = kruskal(*class_groups)\n",
    "    p_values.append(p_val)\n",
    "\n",
    "\n",
    "adjusted_p_values = [p * len(p_values) for p in p_values]\n",
    "\n",
    "# Select features with p-value below the significance level\n",
    "significant_features = [i for i, p_val in enumerate(adjusted_p_values) if p_val < 0.05]\n",
    "\n",
    "print(f'Number of significant features: {len(significant_features)}')\n",
    "# print(f'Significant features: {significant_features}')\n",
    "\n",
    "print('The absence of significant features suggests that the classes may not be well-separated in the original feature space,\\n which could make it challenging for PCA and t-SNE to clearly distinguish between them.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t_SNE in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "features = ptbdb_train.iloc[:, :-1]\n",
    "labels = ptbdb_train.iloc[:, -1]\n",
    "\n",
    "# Reduce dimensionality with PCA\n",
    "pca = PCA(n_components=50)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne_results = tsne.fit_transform(features_pca)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(16,10))\n",
    "unique_labels = labels.unique()\n",
    "label_to_number = {label: number for number, label in enumerate(unique_labels)}\n",
    "colors = labels.map(label_to_number)\n",
    "\n",
    "# Define your discrete color scale\n",
    "color_discrete_scale = ['green', 'red']\n",
    "\n",
    "# Create a ListedColormap object with the defined colors\n",
    "cmap = ListedColormap(color_discrete_scale[:len(unique_labels)])\n",
    "\n",
    "scatter = plt.scatter(tsne_results[:,0], tsne_results[:,1], c=colors, cmap=cmap, alpha=0.5)\n",
    "plt.title('t-SNE visualization of MIT-test dataset')\n",
    "plt.xlabel('t-SNE axis 1')\n",
    "plt.ylabel('t-SNE axis 2')\n",
    "\n",
    "# Create a legend with the correct labels\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, unique_labels, title='Class')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform t_SNE in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "features = ptbdb_test.iloc[:, :-1]\n",
    "labels = ptbdb_test.iloc[:, -1]\n",
    "\n",
    "# Reduce dimensionality with PCA\n",
    "pca = PCA(n_components=50)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne_results = tsne.fit_transform(features_pca)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(16,10))\n",
    "unique_labels = labels.unique()\n",
    "label_to_number = {label: number for number, label in enumerate(unique_labels)}\n",
    "colors = labels.map(label_to_number)\n",
    "\n",
    "# Define your discrete color scale\n",
    "color_discrete_scale = ['green', 'red']\n",
    "\n",
    "# Create a ListedColormap object with the defined colors\n",
    "cmap = ListedColormap(color_discrete_scale[:len(unique_labels)])\n",
    "\n",
    "scatter = plt.scatter(tsne_results[:,0], tsne_results[:,1], c=colors, cmap=cmap, alpha=0.5)\n",
    "plt.title('t-SNE visualization of PTBDB-test dataset')\n",
    "plt.xlabel('t-SNE axis 1')\n",
    "plt.ylabel('t-SNE axis 2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=['Normal', 'Abnormal'], title='Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform UMAP in training set (UMAP das not work for me, HELP!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umap import UMAP\n",
    "# # Drop target column from the training data\n",
    "# features = ptbdb_train.drop(columns=['target'])\n",
    "\n",
    "# # Apply UMAP\n",
    "# umap_model = UMAP(n_components=2, random_state=42)  # Instantiate UMAP model\n",
    "# df_umap = umap_model.fit_transform(features)  # Fit and transform the data\n",
    "\n",
    "# # Define color mapping for target labels\n",
    "# label_to_color = {0: 'red', 1: 'green'}  # Assuming 0 is Abnormal, 1 is Normal\n",
    "# colors = ptbdb_train['target'].map(label_to_color)\n",
    "\n",
    "# # Create the plot\n",
    "# plt.figure(figsize=(16, 10))\n",
    "\n",
    "# # Scatter plot of UMAP results\n",
    "# scatter = plt.scatter(df_umap[:, 0], df_umap[:, 1], c=colors, alpha=0.5)\n",
    "\n",
    "# # Create a custom legend\n",
    "# handles = [\n",
    "#     plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Abnormal'),\n",
    "#     plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Normal')\n",
    "# ]\n",
    "\n",
    "# plt.title('UMAP Visualization of PTBDB Train Dataset')\n",
    "# plt.xlabel('UMAP Axis 1')\n",
    "# plt.ylabel('UMAP Axis 2')\n",
    "# plt.legend(handles=handles, title='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform UMAP in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umap import UMAP\n",
    "# # Drop target column from test data\n",
    "# features = ptbdb_test.drop(columns=['target'])\n",
    "\n",
    "# # Apply UMAP\n",
    "# umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "# df_umap = umap_model.fit_transform(features)\n",
    "\n",
    "# # Get unique labels and create a mapping\n",
    "# unique_labels = ptbdb_test['target'].unique()\n",
    "# label_to_color = {0: 'red', 1: 'green'}\n",
    "# colors = ptbdb_test['target'].map(label_to_color)\n",
    "\n",
    "# # Create the plot\n",
    "# plt.figure(figsize=(16, 10))\n",
    "\n",
    "# # Scatter plot of UMAP results\n",
    "# scatter = plt.scatter(df_umap[:, 0], df_umap[:, 1], c=colors, cmap='viridis', alpha=0.5)\n",
    "\n",
    "# # Create a custom legend\n",
    "# handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Abnormal'),\n",
    "#            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Normal')]\n",
    "\n",
    "# plt.title('UMAP Visualization of PTBDB Test Dataset')\n",
    "# plt.xlabel('UMAP Axis 1')\n",
    "# plt.ylabel('UMAP Axis 2')\n",
    "# plt.legend(handles=handles, title='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for modeling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases_target_1 = ptbdb_train['target'].value_counts()[1] # [1] =  Normal\n",
    "print(\"1 = Normal:\", num_cases_target_1)\n",
    "\n",
    "num_cases_target_0 = ptbdb_train['target'].value_counts()[0] # [0] = Abnormal\n",
    "print(\"0 = Abnormal:\",num_cases_target_0) # Attention: The Coding for target is exactly the opposite of the MIT-BIH dataset!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and split cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file_path = 'ptbdb_train_clean.csv'\n",
    "test_file_path = 'ptbdb_test_clean.csv'\n",
    "\n",
    "# If the cleaned data files do not exist, save them\n",
    "if not os.path.isfile(train_file_path) or not os.path.isfile(test_file_path):\n",
    "    # Read the data\n",
    "    # Encode the labels\n",
    "    ptbdb_train['target'] = ptbdb_train['target'].replace({'Normal': 1, 'Abnormal': 0})\n",
    "    ptbdb_test['target'] = ptbdb_test['target'].replace({'Normal': 1, 'Abnormal': 0})\n",
    "\n",
    "    # Save cleaned data\n",
    "    ptbdb_train.to_csv(train_file_path, index=False)\n",
    "    ptbdb_test.to_csv(test_file_path, index=False)\n",
    "else:\n",
    "    print(\"Cleaned data files already exist.\")\n",
    "\n",
    "# Read cleaned data\n",
    "try:\n",
    "    ptbdb_train = pd.read_csv(train_file_path, header=0)\n",
    "    ptbdb_test = pd.read_csv(test_file_path, header=0)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {train_file_path} or {test_file_path} does not exist.\")\n",
    "    # Optionally, add code to handle this case, e.g., exit or retry\n",
    "\n",
    "# Show the distribution of the two classes\n",
    "print('Class distribution in training\\n', ptbdb_train['target'].value_counts(normalize=True))\n",
    "print('\\nClass distribution in test\\n', ptbdb_test['target'].value_counts(normalize=True))\n",
    "print('\\n')\n",
    "\n",
    "# Plot a pie chart for training data class distribution\n",
    "label_counts = ptbdb_train['target'].value_counts(normalize=True)\n",
    "colors = ['green', 'red']\n",
    "labels = ['Normal', 'Abnormal']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(label_counts, labels=labels, colors=colors, autopct='%1.1f%%')\n",
    "plt.title('Percentage of Each Label in Training Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X_train = ptbdb_train.drop(columns=['target'])\n",
    "y_train = ptbdb_train['target']\n",
    "\n",
    "X_test = ptbdb_test.drop(columns=['target'])\n",
    "y_test = ptbdb_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the distribution of our variables, follow the normal distribution or not\n",
    "from scipy.stats import kstest\n",
    "normal_vars = []\n",
    "non_normal_vars = []\n",
    "\n",
    "for i in range(187):  # 0 to 186\n",
    "    stat, p = kstest(X_train.iloc[:, i], 'norm')\n",
    "    if p > 0.05:\n",
    "        normal_vars.append(f'Variable {i}')\n",
    "    else:\n",
    "        non_normal_vars.append(f'Variable {i}')\n",
    "\n",
    "print(\"Variables following normal distribution:\")\n",
    "print(normal_vars)\n",
    "if len(non_normal_vars) == 187:\n",
    "    print(\"Since our variables do not follow a normal distribution, it is advisable to use scaling methods such as MinMaxScaler or RobustScaler, which are better suited for data that does not conform to a normal distribution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling ensures that all features contribute equally to the model, preventing features with larger ranges from dominating the learning process\n",
    "\n",
    "# Define recommended scalers\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),\n",
    "    \"MinMaxScaler\": MinMaxScaler(),\n",
    "    \"RobustScaler\": RobustScaler()\n",
    "}\n",
    "\n",
    "# Define models to evaluate\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"SVM\": SVC(class_weight='balanced'),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "def evaluate_scalers(X, y, scalers, models):\n",
    "    results = {}\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        print(f\"Scaler: {scaler_name}\", end=\"\\n\\n\")\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            f_score = []\n",
    "            print(f\"Model: {model_name}\", end=\"\\n\\n\")\n",
    "\n",
    "            for train_index, test_index in skf.split(X_scaled, y):\n",
    "                X_train_, y_train_ = X_scaled[train_index], y[train_index]\n",
    "                X_test_, y_test_ = X_scaled[test_index], y[test_index]\n",
    "\n",
    "                model.fit(X_train_, y_train_)\n",
    "\n",
    "                y_pred_ = model.predict(X_test_)\n",
    "\n",
    "                f_score.append(f1_score(y_test_, y_pred_))\n",
    "\n",
    "            mean_f1_score = np.mean(f_score)\n",
    "            print(\"The scores: \", end=\"\\n\\n\")\n",
    "            print([round(f, 2) for f in f_score], end=\"\\n\\n\")\n",
    "            print('F1-Score mean=%.5f' % (mean_f1_score), end=\"\\n\\n\")\n",
    "\n",
    "            if scaler_name not in results:\n",
    "                results[scaler_name] = {}\n",
    "            results[scaler_name][model_name] = mean_f1_score\n",
    "    return results\n",
    "\n",
    "# Apply evaluation\n",
    "results = evaluate_scalers(X_train, y_train, scalers, models)\n",
    "# Summarize the results\n",
    "for scaler_name, model_scores in results.items():\n",
    "    print(f\"Scaler: {scaler_name}\")\n",
    "    for model_name, score in model_scores.items():\n",
    "        print(f\"  Model: {model_name}, F1-Score mean: {score:.5f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the best rescaling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best scaler based on the highest average F1-score\n",
    "best_scaler_name = max(results, key=lambda k: np.mean(list(results[k].values())))\n",
    "best_scaler = scalers[best_scaler_name]\n",
    "print(f\"Best Scaler: {best_scaler_name}\")\n",
    "\n",
    "print(\"In general, the models perform best with StandardScaler. However, the differences in performance are very small. Random Forest was the best performing model, followed by Gradient Boosting. Logistic Regression and SVM performed the worst.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best scaler on the training data and transform it\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Transform the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Convert the numpy arrays to pandas DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the best resampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When dealing with imbalanced datasets, especially those that reflect real-world scenarios,\n",
    "# it’s important to use both resampling methods and appropriate loss functions to improve model performance.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "def crossvalidation(X, y, models):\n",
    "    resampling_methods = {\n",
    "        \"SMOTE\": SMOTE(),\n",
    "        \"Oversampling\": RandomOverSampler(sampling_strategy='not majority'),\n",
    "        \"Undersampling\": RandomUnderSampler(sampling_strategy='majority'),\n",
    "        \"BalancedRandomForest\": BalancedRandomForestClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    results = {}\n",
    "\n",
    "    for name, resample in resampling_methods.items():\n",
    "        print(name, end=\"\\n\\n\")\n",
    "        results[name] = {}\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            f_score = []\n",
    "            print(f\"Model: {model_name}\", end=\"\\n\\n\")\n",
    "\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                X_train_, y_train_ = X.loc[train_index], y.loc[train_index]\n",
    "                X_test_, y_test_ = X.loc[test_index], y.loc[test_index]\n",
    "\n",
    "                if name == \"BalancedRandomForest\":\n",
    "                    model.fit(X_train_, y_train_)\n",
    "                else:\n",
    "                    X_train_resampled, y_train_resampled = resample.fit_resample(X_train_, y_train_)\n",
    "                    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "                y_pred_ = model.predict(X_test_)\n",
    "\n",
    "                f_score.append(f1_score(y_test_, y_pred_))\n",
    "\n",
    "            results[name][model_name] = np.mean(f_score)\n",
    "            print(\"The scores: \", end=\"\\n\\n\")\n",
    "            print([round(f, 2) for f in f_score], end=\"\\n\\n\")\n",
    "            print('F1-Score mean=%.5f' % (np.mean(f_score)), end=\"\\n\\n\")\n",
    "\n",
    "    return results, resampling_methods\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Apply cross-validation with resampling\n",
    "results_resample, resampling_methods = crossvalidation(X_train_scaled, y_train, models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and Apply the best Resampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"Results with Resampling:\")\n",
    "print(results_resample)\n",
    "\n",
    "# Determine the best resampling method\n",
    "best_method = max(results_resample, key=lambda k: np.mean(list(results_resample[k].values())))\n",
    "print(f\"\\nBest Resampling Method: {best_method}\")\n",
    "\n",
    "# Apply the best resampling method to the entire dataset\n",
    "best_resampler = resampling_methods[best_method]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the resampler on the training data and transform it\n",
    "# x_train_resampled, y_train_resampled = best_resampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# # Convert the numpy arrays to pandas DataFrames\n",
    "# X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "# y_train_resampled = pd.Series(y_train_resampled)\n",
    "\n",
    "# # Fit the model on the resampled training data\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Predict the target values\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# # Calculate the F1-score\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# print(f\"F1-Score: {f1:.5f}\")\n",
    "\n",
    "# # Calculate the confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
