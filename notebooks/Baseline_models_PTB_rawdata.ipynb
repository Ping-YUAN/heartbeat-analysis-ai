{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Models and optimization steps for raw PTB data\n",
        " (Logistic Regression, KNN, Naive Bayes, Random Forest)\n",
        "\n",
        "as a seperate file we have applied decision tree model on PTB data (run the notebook: modeling_ptb_decision_tree.ipynb)\n",
        "\n",
        "\n",
        "Input file: raw data\n",
        "\n",
        "ptbdb_test_clean.csv\n",
        "ptbdb_train_clean.csv\n",
        "\n",
        "Output:\n",
        "accuracy and classification reports of each model"
      ],
      "metadata": {
        "id": "Gwz-SOX1wMbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "data_path = ''\n",
        "model_output_path = ''\n",
        "# check if the enviorment is Google Colab\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Running on Google Colab\")\n",
        "    # Install required libraries\n",
        "    # !pip install scikit-learn -q\n",
        "    # !pip install pandas -q\n",
        "    # !pip install numpy -q\n",
        "    # !pip install imbalanced-learn -q\n",
        "\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # set the path where the csv file stored in your google drive.\n",
        "    data_path = '/content/drive/MyDrive/Heartbeat_Project_me/preprocessed_data/'\n",
        "    model_output_path = '/content/drive/MyDrive/Heartbeat_Project_me/model_output/'\n",
        "\n",
        "else:\n",
        "    print(\"Running on local environment\")\n",
        "\n",
        "    current_path = os.getcwd()\n",
        "    print(\"Current working directory:\", current_path)\n",
        "    data_path = '../data/processed/'\n",
        "    model_output_path = '../models/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjcKZtbJpLIo",
        "outputId": "23be6256-aa11-4eb2-c28e-327b9f4d9857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxLUweCPpEAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117ac2cd-31d0-4db8-9f1c-8f95e3e66ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8131226382686362\n",
            "Logistic Regression Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.57      0.64       838\n",
            "           1       0.84      0.91      0.87      2073\n",
            "\n",
            "    accuracy                           0.81      2911\n",
            "   macro avg       0.78      0.74      0.76      2911\n",
            "weighted avg       0.81      0.81      0.81      2911\n",
            "\n",
            "KNN Accuracy: 0.932669185846788\n",
            "KNN Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       838\n",
            "           1       0.96      0.94      0.95      2073\n",
            "\n",
            "    accuracy                           0.93      2911\n",
            "   macro avg       0.91      0.92      0.92      2911\n",
            "weighted avg       0.93      0.93      0.93      2911\n",
            "\n",
            "Naive Bayes Accuracy: 0.602885606320852\n",
            "Naive Bayes Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.81      0.54       838\n",
            "           1       0.87      0.52      0.65      2073\n",
            "\n",
            "    accuracy                           0.60      2911\n",
            "   macro avg       0.64      0.67      0.60      2911\n",
            "weighted avg       0.74      0.60      0.62      2911\n",
            "\n",
            "Random Forest Accuracy: 0.9742356578495363\n",
            "Random Forest Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95       838\n",
            "           1       0.98      0.99      0.98      2073\n",
            "\n",
            "    accuracy                           0.97      2911\n",
            "   macro avg       0.97      0.96      0.97      2911\n",
            "weighted avg       0.97      0.97      0.97      2911\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "RawFiles = dict({\n",
        "    'test': data_path + 'ptbdb_test_clean.csv', # Standard Sscaled data already\n",
        "    'train': data_path + 'ptbdb_train_clean.csv', # Standard Sscaled data already\n",
        "})\n",
        "\n",
        "OutputFiles = dict({\n",
        "    'model': model_output_path +  'baseline_models_PTB_raw.csv',\n",
        "    'Optimization' : model_output_path + 'optimization_baseline_models_PTB_raw.csv'\n",
        "})\n",
        "\n",
        "\n",
        "train = pd.read_csv(RawFiles.get('train'),sep=',',header=0)\n",
        "\n",
        "test = pd.read_csv(RawFiles.get('test'),sep=',',header=0)\n",
        "\n",
        "y_train = train['target']\n",
        "X_train = train.drop('target', axis=1)\n",
        "\n",
        "y_test = test['target']\n",
        "X_test = test.drop('target', axis=1)\n",
        "\n",
        "# Baseline model 1: Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=500)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
        "print(\"Logistic Regression Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Baseline model 2: KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn_model = knn_model.predict(X_test)\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn_model))\n",
        "print(\"KNN Report:\\n\", classification_report(y_test, y_pred_knn_model))\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Baseline model 3: Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Naive Bayes Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Baseline model 4: Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Report:\\n\", classification_report(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model 2: Decision Tree\n",
        "dec_tree = DecisionTreeClassifier()\n",
        "dec_tree.fit(X_train, y_train)\n",
        "y_pred_dec_tree = dec_tree.predict(X_test)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dec_tree))\n",
        "print(\"Decision Tree Report:\\n\", classification_report(y_test, y_pred_dec_tree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Bv0M7r3C5L",
        "outputId": "cbdafc08-78a8-4e1e-cd13-bbbcd8c19480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9223634489866025\n",
            "Decision Tree Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       838\n",
            "           1       0.95      0.94      0.95      2073\n",
            "\n",
            "    accuracy                           0.92      2911\n",
            "   macro avg       0.90      0.91      0.91      2911\n",
            "weighted avg       0.92      0.92      0.92      2911\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Function to evaluate models and store results\n",
        "def evaluate_model(model, X_test, y_test, model_name, results):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Classification Report:\\n {classification_report(y_test, y_pred)}\")\n",
        "    results[model_name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': report['weighted avg']['precision'],\n",
        "        'recall': report['weighted avg']['recall'],\n",
        "        'f1-score': report['weighted avg']['f1-score']\n",
        "    }\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Baseline model 1: Logistic Regression\n",
        "evaluate_model(log_reg, X_test, y_test, \"Logistic Regression\", results)\n",
        "\n",
        "# Baseline model 2: KNN\n",
        "evaluate_model(knn_model, X_test, y_test, \"KNN\", results)\n",
        "\n",
        "\n",
        "# Baseline model 3: Naive Bayes\n",
        "evaluate_model(nb, X_test, y_test, \"Naive Bayes\", results)\n",
        "\n",
        "# Baseline model 4: Random Forest\n",
        "evaluate_model(rf, X_test, y_test, \"Random Forest\", results)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nComparison of Baseline Models:\")\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z0BP9ugphem",
        "outputId": "42e80fd2-5627-4fbd-ba8b-d93511c24558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.7877018206801787\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.83      0.69       814\n",
            "           1       0.92      0.77      0.84      2097\n",
            "\n",
            "    accuracy                           0.79      2911\n",
            "   macro avg       0.75      0.80      0.76      2911\n",
            "weighted avg       0.83      0.79      0.80      2911\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.908278941944349\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.95      0.85       814\n",
            "           1       0.98      0.89      0.93      2097\n",
            "\n",
            "    accuracy                           0.91      2911\n",
            "   macro avg       0.88      0.92      0.89      2911\n",
            "weighted avg       0.92      0.91      0.91      2911\n",
            "\n",
            "Naive Bayes:\n",
            "Accuracy: 0.6214359326691858\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.83      0.55       814\n",
            "           1       0.89      0.54      0.67      2097\n",
            "\n",
            "    accuracy                           0.62      2911\n",
            "   macro avg       0.65      0.68      0.61      2911\n",
            "weighted avg       0.76      0.62      0.64      2911\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.9766403297835795\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       814\n",
            "           1       0.98      0.98      0.98      2097\n",
            "\n",
            "    accuracy                           0.98      2911\n",
            "   macro avg       0.97      0.97      0.97      2911\n",
            "weighted avg       0.98      0.98      0.98      2911\n",
            "\n",
            "\n",
            "Comparison of Baseline Models:\n",
            "                     accuracy  precision    recall  f1-score\n",
            "Logistic Regression  0.787702   0.826942  0.787702  0.796676\n",
            "KNN                  0.908279   0.921501  0.908279  0.910864\n",
            "Naive Bayes          0.621436   0.756003  0.621436  0.638837\n",
            "Random Forest        0.976640   0.976640  0.976640  0.976640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "results = {}\n",
        "# Hyperparameter tuning for Logistic Regression\n",
        "param_grid_log_reg = {'C': [0.1, 1, 10, 100]}\n",
        "grid_log_reg = GridSearchCV(LogisticRegression(), param_grid_log_reg, cv=3, n_jobs=-1)\n",
        "grid_log_reg.fit(X_train, y_train)\n",
        "best_log_reg = grid_log_reg.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_log_reg.best_params_}\")\n",
        "evaluate_model(best_log_reg, X_test, y_test, \"Tuned Logistic Regression\", results)\n",
        "\n",
        "\n",
        "# Hyperparameter tuning for KNN\n",
        "param_grid_knn = {\n",
        "     'n_neighbors': [3, 5, 9, 11],\n",
        "     'weights': ['uniform', 'distance'],\n",
        "     'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "     }\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, n_jobs=-1)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "best_KNN = grid_knn.best_estimator_\n",
        "print(f\"Best parameters for KNN: {grid_knn.best_params_}\")\n",
        "evaluate_model(best_KNN, X_test, y_test, \"Tuned KNN\", results)\n",
        "\n",
        "\n",
        "# # Hyperparameter tuning for Support Vector Machine\n",
        "# param_grid_svm = {'C': [0.1, 10, 100], 'kernel': ['linear']}\n",
        "# grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=3, n_jobs=-1)\n",
        "# grid_svm.fit(X_train, y_train)\n",
        "# evaluate_model(grid_svm, X_test, y_test, \"Tuned SVM\", results)\n",
        "\n",
        "# Hyperparameter tuning for Naive Bayes\n",
        "param_grid_nb = {'var_smoothing': [1e-9, 1e-8, 1e-7]}\n",
        "grid_nb = GridSearchCV(GaussianNB(), param_grid_nb, cv=3, n_jobs=-1)\n",
        "grid_nb.fit(X_train, y_train)\n",
        "best_nb = grid_nb.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_nb.best_params_}\")\n",
        "evaluate_model(best_nb, X_test, y_test, \"Tuned Naive Bayes\", results)\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "best_rf = grid_rf.best_estimator_\n",
        "print(f\"Best parameters for Logistic Regression: {grid_rf.best_params_}\")\n",
        "evaluate_model(best_rf, X_test, y_test, \"Tuned Random Forest\", results)\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df_grid = pd.DataFrame(results).T\n",
        "print(\"\\nComparison of Hyperparameter Tuned Models:\")\n",
        "print(results_df_grid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A77OKJT1pieZ",
        "outputId": "5cfceb84-857e-4d70-97f9-9a39cbd16659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Logistic Regression: {'C': 100}\n",
            "Tuned Logistic Regression:\n",
            "Accuracy: 0.7842665750601168\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.83      0.68       814\n",
            "           1       0.92      0.77      0.84      2097\n",
            "\n",
            "    accuracy                           0.78      2911\n",
            "   macro avg       0.75      0.80      0.76      2911\n",
            "weighted avg       0.82      0.78      0.79      2911\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Tuned KNN:\n",
            "Accuracy: 0.95499828237719\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92       814\n",
            "           1       0.99      0.95      0.97      2097\n",
            "\n",
            "    accuracy                           0.95      2911\n",
            "   macro avg       0.93      0.96      0.95      2911\n",
            "weighted avg       0.96      0.95      0.96      2911\n",
            "\n",
            "Best parameters for Logistic Regression: {'var_smoothing': 1e-09}\n",
            "Tuned Naive Bayes:\n",
            "Accuracy: 0.6214359326691858\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.83      0.55       814\n",
            "           1       0.89      0.54      0.67      2097\n",
            "\n",
            "    accuracy                           0.62      2911\n",
            "   macro avg       0.65      0.68      0.61      2911\n",
            "weighted avg       0.76      0.62      0.64      2911\n",
            "\n",
            "Best parameters for Logistic Regression: {'max_depth': 30, 'n_estimators': 100}\n",
            "Tuned Random Forest:\n",
            "Accuracy: 0.9769838543455857\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96       814\n",
            "           1       0.98      0.98      0.98      2097\n",
            "\n",
            "    accuracy                           0.98      2911\n",
            "   macro avg       0.97      0.97      0.97      2911\n",
            "weighted avg       0.98      0.98      0.98      2911\n",
            "\n",
            "\n",
            "Comparison of Hyperparameter Tuned Models:\n",
            "                           accuracy  precision    recall  f1-score\n",
            "Tuned Logistic Regression  0.784267   0.824290  0.784267  0.793445\n",
            "Tuned KNN                  0.954998   0.958287  0.954998  0.955663\n",
            "Tuned Naive Bayes          0.621436   0.756003  0.621436  0.638837\n",
            "Tuned Random Forest        0.976984   0.976975  0.976984  0.976980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame as a CSV file\n",
        "results_df.to_csv(OutputFiles['model'], index=False)\n",
        "print(f\"DataFrame saved as CSV file at: {OutputFiles['model']}\")\n",
        "\n",
        "results_df_grid.to_csv(OutputFiles['Optimization'], index=False)\n",
        "print(f\"DataFrame saved as CSV file at: {OutputFiles['Optimization']}\")"
      ],
      "metadata": {
        "id": "Dtr70YA7STfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dab09a0-f52a-413f-aed5-550f1eaaf070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as CSV file at: /content/drive/MyDrive/Heartbeat_Project_me/model_output/baseline_models_PTB.csv\n",
            "DataFrame saved as CSV file at: /content/drive/MyDrive/Heartbeat_Project_me/model_output/optimization_baseline_models_PTB.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "# Display the running time\n",
        "print(\"Current time:\", datetime.now())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5vWQs1mcdCj",
        "outputId": "ad6a64f8-83dc-44a3-e5ea-bcf2e185b620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current time: 2024-11-06 14:08:57.926304\n"
          ]
        }
      ]
    }
  ]
}